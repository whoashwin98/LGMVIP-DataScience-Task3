{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62608a2a",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331e838",
   "metadata": {},
   "source": [
    "Here, we will classify handwritten digits using a simple neural network which has only input and output layers. We will than add a hidden layer and see how the performance of the model improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddbf4c",
   "metadata": {},
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59feb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6997a8e",
   "metadata": {},
   "source": [
    "### Import the data using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6251b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# already splitting into training and testing data\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a4f9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fe9033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122d211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking a random image\n",
    "plt.imshow(X_train[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fad0059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output for the particular image\n",
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ba1b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf451c7",
   "metadata": {},
   "source": [
    "We bring the data in the range (0,1). This is done to facilitate data analysis and modeling, and to reduce the impact of different scales on the accuracy of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c495ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80d15b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.48627451, 0.99215686,\n",
       "        1.        , 0.24705882, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37647059, 0.95686275, 0.98431373,\n",
       "        0.99215686, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.49803922, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.9254902 , 0.98431373, 0.82745098,\n",
       "        0.12156863, 0.03137255, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23529412, 0.89411765, 0.98431373, 0.98431373, 0.36862745,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.60784314, 0.99215686, 0.99215686, 0.74117647, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07843137,\n",
       "        0.99215686, 0.98431373, 0.92156863, 0.25882353, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.80392157,\n",
       "        0.99215686, 0.98431373, 0.49411765, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40784314, 0.98431373,\n",
       "        0.99215686, 0.72156863, 0.05882353, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31372549, 0.94117647, 0.98431373,\n",
       "        0.75686275, 0.09019608, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1254902 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.62352941, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.59215686, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.15294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18823529, 0.86666667, 0.98431373, 0.98431373, 0.6745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.91764706, 0.98431373, 0.98431373, 0.76862745, 0.04705882,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.34901961, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.62352941,\n",
       "        1.        , 0.99215686, 0.99215686, 0.12156863, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18823529, 0.89411765,\n",
       "        0.99215686, 0.96862745, 0.54901961, 0.03137255, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25098039, 0.98431373,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25098039, 0.98431373,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09411765, 0.75686275,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2949bc30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313725, 0.58823529, 0.99215686,\n",
       "        0.79215686, 0.12156863, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509804, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.41960784, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08235294, 0.77254902, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.41960784, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43137255, 0.74509804, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.6627451 , 0.42745098, 0.24313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.8627451 , 0.2       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.71372549,\n",
       "        1.        , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.91764706, 0.87058824, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24705882, 0.86666667,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.57647059,\n",
       "        0.30196078, 0.24313725, 0.50196078, 0.98431373, 0.98431373,\n",
       "        0.41176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1254902 , 0.90588235, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.8627451 , 0.5372549 , 0.03921569,\n",
       "        0.        , 0.        , 0.12156863, 0.90196078, 0.98431373,\n",
       "        0.95294118, 0.44313725, 0.01960784, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509804, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.7372549 , 0.07843137, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42745098, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509804, 0.98431373, 0.98431373,\n",
       "        0.78823529, 0.11764706, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.12156863, 0.78431373,\n",
       "        0.99215686, 0.98431373, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14509804, 0.99215686, 0.99215686,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.79215686,\n",
       "        1.        , 0.99215686, 0.64313725, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.54901961, 0.98431373, 0.98431373,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42745098, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.85098039, 0.98431373, 0.98431373,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08235294, 0.24705882, 0.90588235, 0.98431373,\n",
       "        0.99215686, 0.90196078, 0.11764706, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.85098039, 0.98431373, 0.98431373,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.56470588, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.86666667, 0.23921569, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.85098039, 0.98431373, 0.98431373,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.71372549, 0.86666667, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.70588235, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.85490196, 0.99215686, 0.99215686,\n",
       "        0.28627451, 0.28627451, 0.89411765, 0.99215686, 0.99215686,\n",
       "        1.        , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44313725, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.57647059,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.90196078, 0.98431373,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.90196078, 0.74117647, 0.1372549 , 0.03921569,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24313725, 0.55686275,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.41960784, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28235294, 0.68235294, 0.98431373, 0.67843137, 0.27843137,\n",
       "        0.28235294, 0.11764706, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b996ee5",
   "metadata": {},
   "source": [
    "The neural network we are designing will be having:\n",
    "1. **28 * 28 = 784 inputs** (given as a single 1D flattened array) \n",
    "2. **10 outputs** which represent the digits from 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a5582d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape(len(X_train), 28*28)\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880495db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flat = X_test.reshape(len(X_test), 28*28)\n",
    "X_test_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83b7f9",
   "metadata": {},
   "source": [
    "### Creating a simple neural network\n",
    "With only input and output layers, and no hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f02895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4659 - accuracy: 0.8793\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3044 - accuracy: 0.9146\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2833 - accuracy: 0.9215\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2731 - accuracy: 0.9235\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2663 - accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2617 - accuracy: 0.9269\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2580 - accuracy: 0.9282\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2552 - accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2533 - accuracy: 0.9305\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2512 - accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28824fb18d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Keras to create a dense layer, since each and every point would be connected \n",
    "# the activation function used here is the sigmoid function\n",
    "model = keras.Sequential([keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')])\n",
    "\n",
    "# adam optimiser is being used, which adapts the learning rate during training to update the model's weights efficiently.\n",
    "# Categorical cross-entropy is used here because it's suitable for multi-class classification problems with integer labels.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# now we train the neural network using the data\n",
    "# each epoch corresponds to one pass over the entire training dataset. \n",
    "model.fit(X_train_flat, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f986c53",
   "metadata": {},
   "source": [
    "### Model evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c638ce87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26783448457717896, 0.9266999959945679]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b053c1",
   "metadata": {},
   "source": [
    "Now we choose a number at random from the 10000 values in the test data and check if the neural network predicts the digit accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.choice(np.arange(0, 10000))\n",
    "plt.imshow(X_test[random_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334ad7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicting the values from the test data\n",
    "y_predict = model.predict(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceaa4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now this array contains some values, the maximum out of these values would indicate the number we want to find\n",
    "y_predict[random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_predict[random_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61661ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the above process for all numbers\n",
    "y_predicted_labels = np.array([np.argmax(i) for i in y_predict])\n",
    "y_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea882502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840b0dd",
   "metadata": {},
   "source": [
    "We make use of a confusion matrix which is a table used to evaluate the performance of a classification model by comparing the predicted labels with the actual labels of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3ea56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666ad26",
   "metadata": {},
   "source": [
    "### Neural network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding two layers, one of output size 200 (which indicates the number of nodes in the hidden layer)\n",
    "# and another of size 10 (which is the actual output layer)\n",
    "model = keras.Sequential([keras.layers.Dense(200, input_shape=(784,), activation='relu'), keras.layers.Dense(10, activation='sigmoid')])\n",
    "# using the same error measures as the previous one\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_flat, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949056a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate this new model\n",
    "model.evaluate(X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the predicted values, and create a new confusion matrix\n",
    "y_predict = model.predict(X_test_flat)\n",
    "y_predict_labels = np.array([np.argmax(i) for i in y_predict])\n",
    "\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c04742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now observe that the number of erroneous outputs are reduced when one hidden layer is introduced\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791415f",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffab32",
   "metadata": {},
   "source": [
    "Thus, we can say that we have successfully implemented a dense neural network using Keras and Tensorflow for classification of handwritten digits. We have also improved the accuracy of the network by adding a hidden layer, which has shown better results of predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
